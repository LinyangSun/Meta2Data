#!/bin/bash
set -e

# Find scripts directory
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"

# Search for scripts directory in multiple possible locations
find_scripts_dir() {
    local search_paths=(
        "${SCRIPT_DIR}/scripts"                          # Development/git repo
        "/usr/local/share/Meta2Data/scripts"             # System install
        "${HOME}/.local/share/Meta2Data/scripts"         # User install
        "${CONDA_PREFIX}/share/Meta2Data/scripts"        # Conda install
        "${PREFIX}/share/Meta2Data/scripts"              # Alternative prefix
    )

    for path in "${search_paths[@]}"; do
        if [[ -d "$path" && -f "$path/AmpliconFunction.sh" ]]; then
            echo "$path"
            return 0
        fi
    done

    echo "ERROR: Scripts directory not found in any location:" >&2
    for path in "${search_paths[@]}"; do
        echo "  - $path" >&2
    done
    return 1
}

SCRIPTS=$(find_scripts_dir)
if [[ $? -ne 0 ]]; then
    echo "❌ ERROR: Cannot find scripts directory"
    exit 1
fi

show_help() {
    cat << EOF
Usage: Meta2Data AmpliconPIP [options]

Download and process amplicon sequencing data based on user provided metadata.

Options:
    -m, --metadata FILE       Input metadata CSV file (required; unless --test is used)
    --col-bioproject Chr     Column name for BioProject in metadata (required; unless --test is used)
    --col-sra Chr            Column name for SRA accession in metadata (required; unless --test is used)

Optional options:
    -o, --output DIR          Output base directory
                              Default: current directory in --test mode
                                       metadata file directory in normal mode
    -t, --threads int         Number of CPU threads (default: 4)
    --gg2                     Enable GreenGenes2 taxonomy assignment after processing
    --i-backbone FILE         Backbone tree file (required if --gg2 is enabled)
    --i-reference-taxonomy FILE Reference taxonomy file (required if --gg2 is enabled)
    --test                    Use test metadata file (test/ampliconpiptest.csv)
                              Output defaults to current directory in test mode
    -h, --help                Show this help message

Column name customization (specify your CSV column names):

Metadata CSV file format:
    Required columns (default names, customizable with --col-* options):
    - Bioproject          : BioProject accession (used as dataset ID, e.g., PRJNA123456)
    - Run                 : SRA run accession (e.g., SRR123456)

Example CSV structure:
    Bioproject,Run
    PRJNA12345,SRR123456
    PRJNA12345,SRR123457

Example usage:
    # Test mode (output to current directory)
    Meta2Data AmpliconPIP --test -t 8

    # Test mode with custom output directory
    Meta2Data AmpliconPIP --test -o /path/to/output/ -t 8

    # Basic usage (output to metadata file directory)
    Meta2Data AmpliconPIP -m /path/to/metadata.csv --col-bioproject Bioproject --col-sra Run -t 8

    # Specify custom output directory
    Meta2Data AmpliconPIP -m /path/a/to/metadata.csv -o /path/b/to/output/ --col-bioproject Bioproject --col-sra Run -t 8

    # Enable GreenGenes2 taxonomy assignment
    Meta2Data AmpliconPIP -m metadata.csv --col-bioproject Bioproject --col-sra Run -t 8 --gg2 --i-backbone backbone.qza --i-reference-taxonomy taxonomy.qza

    # Use test metadata file
    Meta2Data AmpliconPIP --test -t 8

Output structure:
    <output_dir>/
    ├── datasets_ID.txt              # Generated dataset list
    ├── <dataset_ID>/                # One directory per dataset
    │   ├── <dataset_ID>_sra.txt     # SRA accession list
    │   ├── ori_fastq/               # Downloaded FASTQ files
    │   ├── <dataset_ID>-final-rep-seqs.qza       # Final sequences
    │   └── <dataset_ID>-final-table.qza          # Final feature table
    ├── final/                       # (if --gg2 enabled)
    │   └── merged/                  # Merged results with taxonomy
    ├── failed_datasets.log
    ├── success_datasets.log
    └── skipped_datasets.log

EOF
}

# Default parameters
METADATA=""
OUTPUT=""
THREADS=4
ENABLE_GG2=false
TEST_MODE=false
I_BACKBONE=""
I_REFERENCE_TAXONOMY=""

# Initialize column names as empty (no defaults)
COL_BIOPROJECT=""
COL_SRA=""

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -m|--metadata)
            METADATA="$2"
            shift 2
            ;;
        -o|--output)
            OUTPUT="$2"
            shift 2
            ;;
        -t|--threads)
            THREADS="$2"
            shift 2
            ;;
        --gg2)
            ENABLE_GG2=true
            shift
            ;;
        --i-backbone)
            I_BACKBONE="$2"
            shift 2
            ;;
        --i-reference-taxonomy)
            I_REFERENCE_TAXONOMY="$2"
            shift 2
            ;;
        --test)
            TEST_MODE=true
            shift
            ;;
        --col-bioproject)
            COL_BIOPROJECT="$2"
            shift 2
            ;;
        --col-sra)
            COL_SRA="$2"
            shift 2
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            echo "Error: Unknown option '$1'"
            show_help
            exit 1
            ;;
    esac
done

# Handle test mode - set defaults for test mode
if [[ "$TEST_MODE" == true ]]; then
    # Search for test file in multiple possible locations
    TEST_FILE="ampliconpiptest.csv"
    METADATA=""

    # Search paths (in order of preference)
    SEARCH_PATHS=(
        "${SCRIPT_DIR}/test/${TEST_FILE}"                    # Development/git repo
        "/usr/local/share/Meta2Data/test/${TEST_FILE}"       # System install
        "${HOME}/.local/share/Meta2Data/test/${TEST_FILE}"   # User install
        "${CONDA_PREFIX}/share/Meta2Data/test/${TEST_FILE}"  # Conda install
        "${PREFIX}/share/Meta2Data/test/${TEST_FILE}"        # Alternative prefix
    )

    for path in "${SEARCH_PATHS[@]}"; do
        if [[ -f "$path" ]]; then
            METADATA="$path"
            break
        fi
    done

    if [[ -z "$METADATA" ]]; then
        echo "Error: Test metadata file not found in any of these locations:"
        for path in "${SEARCH_PATHS[@]}"; do
            echo "  - $path"
        done
        echo ""
        echo "Hint: The test file may not be included in pip installations."
        echo "      Use -m /path/to/your/metadata.csv instead of --test"
        exit 1
    fi

    # Set default column names for test mode
    COL_BIOPROJECT="Bioproject"
    COL_SRA="Run"
    echo "Test mode enabled: Using $METADATA"
fi

# Validate required parameters
if [[ -z "$METADATA" ]]; then
    echo "Error: --metadata is required (or use --test for test mode)"
    show_help
    exit 1
fi

if [[ -z "$COL_BIOPROJECT" ]]; then
    echo "Error: --col-bioproject is required (or use --test for test mode)"
    show_help
    exit 1
fi

if [[ -z "$COL_SRA" ]]; then
    echo "Error: --col-sra is required (or use --test for test mode)"
    show_help
    exit 1
fi

# Validate GG2-specific parameters
if [[ "$ENABLE_GG2" == true ]]; then
    if [[ -z "$I_BACKBONE" ]]; then
        echo "Error: --i-backbone is required when --gg2 is enabled"
        show_help
        exit 1
    fi
    
    if [[ -z "$I_REFERENCE_TAXONOMY" ]]; then
        echo "Error: --i-reference-taxonomy is required when --gg2 is enabled"
        show_help
        exit 1
    fi
    
    # Check if backbone file exists
    if [[ ! -f "$I_BACKBONE" ]]; then
        echo "Error: Backbone file '$I_BACKBONE' not found"
        exit 1
    fi
    
    # Check if reference taxonomy file exists
    if [[ ! -f "$I_REFERENCE_TAXONOMY" ]]; then
        echo "Error: Reference taxonomy file '$I_REFERENCE_TAXONOMY' not found"
        exit 1
    fi
    
    # Convert to absolute paths
    I_BACKBONE=$(cd "$(dirname "$I_BACKBONE")" && pwd)/$(basename "$I_BACKBONE")
    I_REFERENCE_TAXONOMY=$(cd "$(dirname "$I_REFERENCE_TAXONOMY")" && pwd)/$(basename "$I_REFERENCE_TAXONOMY")
fi

# Check if metadata file exists
if [[ ! -f "$METADATA" ]]; then
    echo "Error: Metadata file '$METADATA' not found"
    exit 1
fi

# Convert metadata to absolute path
METADATA=$(cd "$(dirname "$METADATA")" && pwd)/$(basename "$METADATA")

# Set output directory
if [[ -z "$OUTPUT" ]]; then
    if [[ "$TEST_MODE" == true ]]; then
        # In test mode, default to current working directory
        # (test metadata is inside package, can't write there)
        OUTPUT=$(pwd)
        echo "Output directory not specified, using current directory: $OUTPUT"
    else
        # Normal mode: use metadata file directory
        OUTPUT=$(dirname "$METADATA")
        echo "Output directory not specified, using metadata file directory: $OUTPUT"
    fi
else
    # User specified output directory
    mkdir -p "$OUTPUT"
    OUTPUT=$(cd "$OUTPUT" && pwd)
fi

# Source function library (AmpliconFunction.sh)
# Note: py_16s.py must be in PATH (installed via setup.py or conda env)
if [[ -f "${SCRIPTS}/AmpliconFunction.sh" ]]; then
    source "${SCRIPTS}/AmpliconFunction.sh"
else
    echo "Error: AmpliconFunction.sh not found at ${SCRIPTS}/AmpliconFunction.sh"
    exit 1
fi


# Display configuration
echo "========================================="
echo "Meta2Data AmpliconPIP"
echo "========================================="
echo "Metadata:       $METADATA"
echo "Output:         $OUTPUT"
echo "Threads:        $THREADS"
echo "GG2 Taxonomy:   $ENABLE_GG2"
if [[ "$ENABLE_GG2" == true ]]; then
    echo "Backbone:       $I_BACKBONE"
    echo "Ref Taxonomy:   $I_REFERENCE_TAXONOMY"
fi
echo "BioProject Col: $COL_BIOPROJECT"
echo "SRA Col:        $COL_SRA"
echo "========================================="
echo ""

# Export environment variables
export cpu=$THREADS

################################################################################
#                    AMPLICON PROCESSING PIPELINE                              #
################################################################################

echo "========================================="
echo "Running Amplicon Processing Pipeline"
echo "Started: $(date)"
echo "========================================="
echo ""

# Call run.sh to handle all processing
if ! bash "${SCRIPTS}/run.sh" \
    -m "$METADATA" \
    -o "$OUTPUT" \
    -t "$THREADS" \
    --col-bioproject "$COL_BIOPROJECT" \
    --col-sra "$COL_SRA"; then
    echo "❌ ERROR: Amplicon processing pipeline failed"
    echo "Check logs in: $OUTPUT"
    exit 1
fi

echo ""
echo "✓ Amplicon processing completed successfully"
echo ""

################################################################################
#                  TAXONOMY ASSIGNMENT (if enabled)                            #
################################################################################

if [[ "$ENABLE_GG2" == true ]]; then
    echo "========================================="
    echo "Running GreenGenes2 Taxonomy Assignment"
    echo "Started: $(date)"
    echo "========================================="
    echo ""

    # Export OUTPUT for taxonomy.sh
    export OUTPUT

    # Call taxonomy.sh for GreenGenes2 annotation with required parameters
    if ! bash "${SCRIPTS}/taxonomy.sh" \
        --i-backbone "$I_BACKBONE" \
        --i-reference-taxonomy "$I_REFERENCE_TAXONOMY"; then
        echo "❌ ERROR: Taxonomy assignment failed"
        echo "Check logs in: $OUTPUT"
        exit 1
    fi

    echo ""
    echo "✓ Taxonomy assignment completed successfully"
    echo ""
fi

################################################################################
#                             Final Summary                                    #
################################################################################

echo "========================================="
echo "PROCESSING COMPLETE"
echo "Finished: $(date)"
echo "========================================="
echo ""

# Display log file locations
failed_log="${OUTPUT}/failed_datasets.log"
success_log="${OUTPUT}/success_datasets.log"
skipped_log="${OUTPUT}/skipped_datasets.log"

if [ -f "$success_log" ]; then
    success_count=$(wc -l < "$success_log" 2>/dev/null | tr -d ' ')
    echo "Successful datasets: $success_count"
fi

if [ -f "$failed_log" ] && [ -s "$failed_log" ]; then
    failed_count=$(wc -l < "$failed_log" 2>/dev/null | tr -d ' ')
    echo "Failed datasets:     $failed_count"
    echo "⚠️  Check: $failed_log"
fi

if [ -f "$skipped_log" ] && [ -s "$skipped_log" ]; then
    skipped_count=$(wc -l < "$skipped_log" 2>/dev/null | tr -d ' ')
    echo "Skipped datasets:    $skipped_count"
fi

echo ""
echo "Results saved in: $OUTPUT"

if [[ "$ENABLE_GG2" == true ]]; then
    echo "Merged results with taxonomy: ${OUTPUT}/final/merged/"
fi

echo "========================================="