#!/bin/bash
set -e

# Find scripts directory
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
SCRIPTS="${SCRIPT_DIR}/scripts/MetaDL"

show_help() {
    cat << EOF
Usage: Meta2Data MetaDL-v2 [options]

Enhanced metadata download pipeline with parallel processing and checkpoints.
Downloads metadata from both NCBI and CNCB/GSA for ALL BioProjects.

NEW FEATURES IN V2.1:
    ✓ Keyword search mode: Search BioProjects by field, organism, and optional terms
    ✓ Auto-generated email: No need to provide email (auto-generated by default)
    ✓ Dual workflow: Keywords mode OR BioProject ID input mode
    ✓ Parallel downloads (8 workers with API key, 3 without)
    ✓ Checkpoint/resume system (no need to restart from scratch)
    ✓ Retry mechanism with exponential backoff
    ✓ Comprehensive logging (file + console)

WORKFLOW MODES:

Mode 1: BioProject ID Input (default)
    Provide a folder with BioProject IDs in .txt files
    Required: -i/--input, -o/--output

Mode 2: Keyword Search
    Search for BioProjects using keywords
    Required: -o/--output, --keywords, --field, --organism
    Optional: --opt

Required options:
    -o, --output DIR          Output directory for metadata

Keyword Search Mode Options:
    --keywords                Enable keyword search mode
    --field "term1" "term2"   Search fields (e.g., "16S rRNA" "amplicon")
    --organism "term1" ...    Organism terms (e.g., "bacteria" "human gut")
    --opt "term1" ...         Optional additional terms (e.g., "Illumina")

BioProject Input Mode Options:
    -i, --input DIR           Input directory containing BioProject ID txt files

Optional options:
    -e, --email EMAIL         Email address (auto-generated if not provided)
    -k, --api-key KEY         NCBI API key (increases rate limits & workers to 8)
    -w, --max-workers NUM     Max parallel workers (default: 8 with key, 3 without)
    -h, --help                Show this help message

Input Format:
    The input directory should contain .txt files with BioProject IDs.
    Each file should have one BioProject ID per line.
    Supports ANY format: PRJNA*, PRJEB*, PRJDB*, PRJCA*, CRA* etc.

    ALL BioProjects will be processed through:
      1. NCBI download (BioSample + SRA via Entrez API)
      2. iSeq download (CNCB/GSA metadata if available)

Output Files:
    Main output:
      - all_metadata_merged.csv      Final merged dataset (NCBI + CNCB)

    Intermediate files:
      - *_biosample.txt              Raw BioSample data (per project)
      - *_sra_runinfo.csv            Raw SRA RunInfo (per project)
      - ncbi_merged_*.csv            Merged NCBI data
      - cncb_combined.csv            Combined CNCB data

    Progress tracking:
      - logs/metadl_v2_*.log         Detailed execution log
      - checkpoints/download_state.json   Resume state (for interrupted runs)

Examples:

    # Mode 1: BioProject ID input (basic)
    Meta2Data MetaDL-v2 \\
        -i bioproject_ids/ \\
        -o metadata_output/

    # Mode 1: With NCBI API key (faster)
    Meta2Data MetaDL-v2 \\
        -i bioproject_ids/ \\
        -o metadata_output/ \\
        -k YOUR_NCBI_API_KEY

    # Mode 2: Keyword search
    Meta2Data MetaDL-v2 \\
        -o metadata_output/ \\
        --keywords \\
        --field "16S rRNA" "amplicon" \\
        --organism "gut microbiome" "soil bacteria"

    # Mode 2: Keyword search with optional terms
    Meta2Data MetaDL-v2 \\
        -o metadata_output/ \\
        --keywords \\
        --field "metagenome" \\
        --organism "human" \\
        --opt "Illumina" "MiSeq"

Workflow:
    1. Read all BioProject IDs from input folder (no classification)
    2. Parallel download from NCBI (BioSample + SRA) - ALL projects
    3. Sequential download from iSeq (CNCB/GSA) - ALL projects
    4. Parse and merge NCBI data (SRA + BioSample)
    5. Parse CNCB data (Excel/CSV conversion)
    6. Final merge: Combine NCBI + CNCB datasets

Features:
    ✓ Resume from checkpoint if interrupted (Ctrl+C safe)
    ✓ Parallel downloads for NCBI (faster than v1)
    ✓ Automatic retry with exponential backoff
    ✓ Detailed logging to file + console
    ✓ Comprehensive error handling
    ✓ Smart merge strategy selection (BioSample ID vs composite key)

Performance:
    - Without API key: ~10 requests/second (3 parallel workers)
    - With API key:    ~30 requests/second (8 parallel workers)
    - Large datasets:  Use --api-key for 3x speedup

Note:
    - NCBI requires an email address for API access
    - Get free API key at: https://www.ncbi.nlm.nih.gov/account/
    - iSeq must be installed (conda install -c bioconda iseq)
    - Interrupted runs can be resumed automatically

EOF
}

# Default parameters
INPUT=""
OUTPUT=""
EMAIL=""
API_KEY=""
MAX_WORKERS=""
KEYWORDS=""
FIELD=()
ORGANISM=()
OPT=()

# Parse arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -i|--input)
            INPUT="$2"
            shift 2
            ;;
        -o|--output)
            OUTPUT="$2"
            shift 2
            ;;
        -e|--email)
            EMAIL="$2"
            shift 2
            ;;
        -k|--api-key)
            API_KEY="$2"
            shift 2
            ;;
        -w|--max-workers)
            MAX_WORKERS="$2"
            shift 2
            ;;
        --keywords)
            KEYWORDS="true"
            shift 1
            ;;
        --field)
            shift
            while [[ $# -gt 0 && ! "$1" =~ ^- ]]; do
                FIELD+=("$1")
                shift
            done
            ;;
        --organism)
            shift
            while [[ $# -gt 0 && ! "$1" =~ ^- ]]; do
                ORGANISM+=("$1")
                shift
            done
            ;;
        --opt)
            shift
            while [[ $# -gt 0 && ! "$1" =~ ^- ]]; do
                OPT+=("$1")
                shift
            done
            ;;
        -h|--help)
            show_help
            exit 0
            ;;
        *)
            echo "Error: Unknown option '$1'"
            show_help
            exit 1
            ;;
    esac
done

# Validate required parameters
if [[ -z "$OUTPUT" ]]; then
    echo "Error: --output is required"
    show_help
    exit 1
fi

# Create output directory
mkdir -p "$OUTPUT"

# Validate mode-specific requirements
if [[ "$KEYWORDS" == "true" ]]; then
    # Keywords mode
    if [[ ${#FIELD[@]} -eq 0 || ${#ORGANISM[@]} -eq 0 ]]; then
        echo "Error: --keywords mode requires both --field and --organism"
        show_help
        exit 1
    fi

    # Log parameters
    echo "=== Meta2Data MetaDL V2.1 - KEYWORD SEARCH MODE ==="
    echo "Output directory: $OUTPUT"
    echo "Field terms:      ${FIELD[*]}"
    echo "Organism terms:   ${ORGANISM[*]}"
    if [[ ${#OPT[@]} -gt 0 ]]; then
        echo "Optional terms:   ${OPT[*]}"
    fi
    if [[ -n "$EMAIL" ]]; then
        echo "Email:            $EMAIL"
    else
        echo "Email:            (auto-generated)"
    fi
    echo "API key:          $(if [[ -n "$API_KEY" ]]; then echo "Yes"; else echo "No"; fi)"
    if [[ -n "$MAX_WORKERS" ]]; then
        echo "Max workers:      $MAX_WORKERS (custom)"
    fi
    echo "===================================================="
    echo ""

    # Build Python command for keywords mode
    PYTHON_CMD=(
        python3 "${SCRIPTS}/unified_metadata_downloader_v2.py"
        --output "$OUTPUT"
        --keywords
    )

    # Add field terms
    PYTHON_CMD+=(--field)
    for term in "${FIELD[@]}"; do
        PYTHON_CMD+=("$term")
    done

    # Add organism terms
    PYTHON_CMD+=(--organism)
    for term in "${ORGANISM[@]}"; do
        PYTHON_CMD+=("$term")
    done

    # Add optional terms if provided
    if [[ ${#OPT[@]} -gt 0 ]]; then
        PYTHON_CMD+=(--opt)
        for term in "${OPT[@]}"; do
            PYTHON_CMD+=("$term")
        done
    fi

else
    # BioProject input mode
    if [[ -z "$INPUT" ]]; then
        echo "Error: --input is required when not using --keywords mode"
        show_help
        exit 1
    fi

    # Check if input directory exists
    if [[ ! -d "$INPUT" ]]; then
        echo "Error: Input directory '$INPUT' not found"
        exit 1
    fi

    # Check if input directory contains txt files
    txt_count=$(find "$INPUT" -maxdepth 1 -name "*.txt" | wc -l)
    if [[ $txt_count -eq 0 ]]; then
        echo "Error: No .txt files found in input directory '$INPUT'"
        echo "Please provide BioProject IDs in .txt files (one ID per line)"
        exit 1
    fi

    # Log parameters
    echo "=== Meta2Data MetaDL V2.1 - BIOPROJECT INPUT MODE ==="
    echo "Input directory:  $INPUT"
    echo "Output directory: $OUTPUT"
    if [[ -n "$EMAIL" ]]; then
        echo "Email:            $EMAIL"
    else
        echo "Email:            (auto-generated)"
    fi
    echo "API key:          $(if [[ -n "$API_KEY" ]]; then echo "Yes (parallel: 8 workers)"; else echo "No (parallel: 3 workers)"; fi)"
    if [[ -n "$MAX_WORKERS" ]]; then
        echo "Max workers:      $MAX_WORKERS (custom)"
    fi
    echo "BioProject files: $txt_count"
    echo "====================================================="
    echo ""

    # Build Python command for BioProject input mode
    PYTHON_CMD=(
        python3 "${SCRIPTS}/unified_metadata_downloader_v2.py"
        --input "$INPUT"
        --output "$OUTPUT"
    )
fi

# Add common optional parameters
if [[ -n "$EMAIL" ]]; then
    PYTHON_CMD+=(--email "$EMAIL")
fi

if [[ -n "$API_KEY" ]]; then
    PYTHON_CMD+=(--api-key "$API_KEY")
fi

if [[ -n "$MAX_WORKERS" ]]; then
    PYTHON_CMD+=(--max-workers "$MAX_WORKERS")
fi

# Call the unified Python script V2
"${PYTHON_CMD[@]}"

EXIT_CODE=$?

if [[ $EXIT_CODE -eq 0 ]]; then
    echo ""
    echo "========================================"
    echo "MetaDL V2.1 completed successfully!"
    echo "========================================"
    echo ""
    echo "Output files are in: $OUTPUT"
    echo ""
    echo "Main output files:"
    echo "  - all_metadata_merged.csv (merged NCBI + CNCB metadata)"
    echo "  - status.tsv              (download status for all BioProjects)"
    echo ""
    if [[ "$KEYWORDS" == "true" ]]; then
        echo "Keyword search results:"
        echo "  - searched_keywords/combined_results.csv  (BioProject search results)"
        echo "  - searched_keywords/search_summary.txt    (query summary)"
        echo ""
    fi
    echo "Additional outputs:"
    echo "  - logs/            (detailed execution logs)"
    echo "  - checkpoints/     (resume state)"
    echo ""
else
    echo ""
    echo "========================================"
    echo "MetaDL V2.1 failed with exit code $EXIT_CODE"
    echo "========================================"
    echo ""
    echo "Check logs in: $OUTPUT/logs/"
    echo "Resume by running the same command again (checkpoints enabled)"
    echo ""
    exit $EXIT_CODE
fi
