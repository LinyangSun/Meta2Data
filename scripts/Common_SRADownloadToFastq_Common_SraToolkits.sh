#!/usr/bin/env bash
Common_SRADownloadToFastq_Common_SraToolkits() {
    local dir_path="" acc=""
    OPTIND=1
    while getopts ":d:a:" opt; do
        case $opt in
            d) dir_path=$OPTARG ;;
            a) acc=$OPTARG ;;
            ?) echo "Unknown Parameter: -$OPTARG" >&2; return 1 ;;
        esac
    done
    if [[ -z "$dir_path" || -z "$acc" ]]; then
        echo "Usage: Common_SRADownloadToFastq_Common_SraToolkits -d <dir> -a <accession_tsv>" >&2
        return 1
    fi
    command -v iseq >/dev/null 2>&1 || { echo "Error: 'iseq' not found. Please install via: conda install bioconda::iseq" >&2; return 1; }
    
    local base_dir="${dir_path%/}/"
    [[ -d "$base_dir" ]] || { echo "Directory not found: $base_dir" >&2; return 1; }
    [[ -r "${base_dir%/}/$acc" ]] || { echo "Accession file not readable: ${base_dir%/}/$acc" >&2; return 1; }

    local fastq_path="${base_dir%/}/ori_fastq/"
    local temp_dl_path="${base_dir%/}/temp_iseq/"
    mkdir -p "$fastq_path" "$temp_dl_path"

    # TSV file format (5 columns generated by py_16s.py):
    # Column 1: SRA accession (e.g., SRR123456)
    # Column 2: Rename prefix (Bioproject-Biosample, e.g., PRJNA123-SAMN123)
    # Column 3: Region (e.g., V4)
    # Column 4: Forward primer sequence
    # Column 5: Reverse primer sequence
    # Note: We only use columns 1 and 2 for downloading and renaming
    # iSeq automatically downloads and converts to FASTQ in one step
    while IFS=$'\t' read -r sra rename region forward reverse; do
        [[ -n "$sra" && -n "$rename" ]] || { echo "Skipping malformed line in $acc" >&2; continue; }

        echo "========================================"
        echo "Downloading $sra with iSeq..."
        echo "========================================"

        # Download using iSeq (automatically handles retry, MD5 check, and FASTQ conversion)
        # -i: input accession
        # -q: convert to uncompressed FASTQ
        # -o: output directory
        # -t: threads for conversion (default 8)
        if iseq -i "$sra" -q -o "$temp_dl_path" -t 8; then
            echo "✓ iSeq download completed for $sra"

            # Rename files with the specified prefix
            # iSeq downloads files as: SRR*_1.fastq, SRR*_2.fastq, or SRR*.fastq
            find "$temp_dl_path" -type f -name "${sra}*.fastq" -print0 |
            while IFS= read -r -d '' file; do
                local basename=$(basename "$file")
                # Replace SRA accession with rename prefix
                local new_name="${basename/$sra/$rename}"
                mv "$file" "${fastq_path%/}/${new_name}"
                echo "Saved: ${fastq_path%/}/${new_name}"
            done

            # Clean up temporary download directory for this accession
            rm -rf "${temp_dl_path:?}/${sra}"*
        else
            echo "❌ ERROR: iSeq download failed for $sra" >&2
            echo "Failed accession: $sra" >> "${base_dir%/}/failed_downloads.log"
        fi

        echo ""
    done < "${base_dir%/}/$acc"
    rm -rf "$temp_dl_path"
    
    # ============================================================
    # Identify and handle mixed datasets
    # ============================================================
    echo "========================================"
    echo "Analyzing dataset sequencing types..."
    echo "========================================"
    
    # Get unique sample prefixes
    declare -A sample_prefixes
    for file in "$fastq_path"/*.fastq; do
        [[ -f "$file" ]] || continue
        local basename=$(basename "$file")
        local prefix="${basename%.fastq}"
        prefix="${prefix%_1}"
        prefix="${prefix%_2}"
        sample_prefixes["$prefix"]=1
    done
    
    # Count samples by type
    local single_samples=0
    local paired_samples=0
    for prefix in "${!sample_prefixes[@]}"; do
        if [[ -f "${fastq_path}/${prefix}_2.fastq" ]]; then
            ((paired_samples++))
        else
            ((single_samples++))
        fi
    done
    
    local total_samples=${#sample_prefixes[@]}
    local report_file="${base_dir%/}/sequencing_type_report.log"
    
    {
        echo "=========================================="
        echo "Dataset: $(basename "${base_dir%/}")"
        echo "Date: $(date)"
        echo "=========================================="
        echo "Total samples: $total_samples"
        echo "Single-end samples: $single_samples"
        echo "Paired-end samples: $paired_samples"
    } | tee "$report_file"
    
    # Check if mixed dataset
    if [ "$single_samples" -gt 0 ] && [ "$paired_samples" -gt 0 ]; then
        echo "⚠️  MIXED dataset detected!" | tee -a "$report_file"
        echo "Processing each sample individually..." | tee -a "$report_file"
        
        # Check if vsearch is available
        if ! command -v vsearch >/dev/null 2>&1; then
            echo "Error: vsearch not found. Cannot merge paired-end reads." >&2
            return 1
        fi
        
        local orphan_count=0
        local paired_count=0
        local single_count=0
        local merged_kept=0
        local forward_kept=0
        
        # Process each sample
        for prefix in "${!sample_prefixes[@]}"; do
            local orphan_file="${fastq_path}/${prefix}.fastq"
            local r1_file="${fastq_path}/${prefix}_1.fastq"
            local r2_file="${fastq_path}/${prefix}_2.fastq"
            local merged_file="${fastq_path}/${prefix}.fastq"
            local final_file="${fastq_path}/${prefix}.fastq"
            
            # Classify sample type
            if [[ -f "$orphan_file" && -f "$r1_file" && -f "$r2_file" ]]; then
                # ORPHAN: 3 files for 1 sample
                echo "  Sample: $prefix [ORPHAN - 3 files]" | tee -a "$report_file"
                ((orphan_count++))
                
                # Delete orphan file
                echo "    Deleting orphan file: $(basename "$orphan_file")" | tee -a "$report_file"
                rm -f "$orphan_file"
                
                # Merge paired files
                echo "    Merging paired files..." | tee -a "$report_file"
                if vsearch --fastq_mergepairs "$r1_file" \
                           --reverse "$r2_file" \
                           --fastqout "$merged_file" \
                           --fastq_minovlen 10 \
                           --fastq_maxdiffs 10 \
                           --quiet 2>/dev/null; then
                    
                    # Get file sizes
                    local r1_size=$(stat -f%z "$r1_file" 2>/dev/null || stat -c%s "$r1_file" 2>/dev/null)
                    local merged_size=$(stat -f%z "$merged_file" 2>/dev/null || stat -c%s "$merged_file" 2>/dev/null)
                    local threshold=$((r1_size / 2))
                    
                    echo "    Forward size: $r1_size bytes, Merged size: $merged_size bytes, Threshold: $threshold bytes" | tee -a "$report_file"
                    
                    if [ "$merged_size" -lt "$threshold" ]; then
                        # Poor merge quality - keep forward only
                        echo "    ⚠️  Merged size < 0.5 × forward → Keeping forward reads only" | tee -a "$report_file"
                        rm -f "$merged_file" "$r2_file"
                        mv "$r1_file" "$final_file"
                        ((forward_kept++))
                    else
                        # Good merge quality - keep merged
                        echo "    ✅ Merged size ≥ 0.5 × forward → Keeping merged reads" | tee -a "$report_file"
                        rm -f "$r1_file" "$r2_file"
                        mv "$merged_file" "$final_file"
                        ((merged_kept++))
                    fi
                else
                    echo "    ❌ Merge failed → Keeping forward reads only" | tee -a "$report_file"
                    rm -f "$r2_file"
                    mv "$r1_file" "$final_file"
                    ((forward_kept++))
                fi
                
            elif [[ -f "$r1_file" && -f "$r2_file" ]]; then
                # PAIRED: 2 files for 1 sample
                echo "  Sample: $prefix [PAIRED - 2 files]" | tee -a "$report_file"
                ((paired_count++))
                
                # Merge paired files
                echo "    Merging paired files..." | tee -a "$report_file"
                if vsearch --fastq_mergepairs "$r1_file" \
                           --reverse "$r2_file" \
                           --fastqout "$merged_file" \
                           --fastq_minovlen 10 \
                           --fastq_maxdiffs 10 \
                           --quiet 2>/dev/null; then
                    
                    # Get file sizes
                    local r1_size=$(stat -f%z "$r1_file" 2>/dev/null || stat -c%s "$r1_file" 2>/dev/null)
                    local merged_size=$(stat -f%z "$merged_file" 2>/dev/null || stat -c%s "$merged_file" 2>/dev/null)
                    local threshold=$((r1_size / 2))
                    
                    echo "    Forward size: $r1_size bytes, Merged size: $merged_size bytes, Threshold: $threshold bytes" | tee -a "$report_file"
                    
                    if [ "$merged_size" -lt "$threshold" ]; then
                        # Poor merge quality - keep forward only
                        echo "    ⚠️  Merged size < 0.5 × forward → Keeping forward reads only" | tee -a "$report_file"
                        rm -f "$merged_file" "$r2_file"
                        mv "$r1_file" "$final_file"
                        ((forward_kept++))
                    else
                        # Good merge quality - keep merged
                        echo "    ✅ Merged size ≥ 0.5 × forward → Keeping merged reads" | tee -a "$report_file"
                        rm -f "$r1_file" "$r2_file"
                        mv "$merged_file" "$final_file"
                        ((merged_kept++))
                    fi
                else
                    echo "    ❌ Merge failed → Keeping forward reads only" | tee -a "$report_file"
                    rm -f "$r2_file"
                    mv "$r1_file" "$final_file"
                    ((forward_kept++))
                fi
                
            else
                # SINGLE: 1 file for 1 sample
                echo "  Sample: $prefix [SINGLE - 1 file] → Skipping" | tee -a "$report_file"
                ((single_count++))
            fi
        done
        
        # Final summary
        {
            echo "=========================================="
            echo "Processing Summary:"
            echo "  Orphan samples (3 files): $orphan_count"
            echo "  Paired samples (2 files): $paired_count"
            echo "  Single samples (1 file): $single_count (skipped)"
            echo "  Samples kept as merged: $merged_kept"
            echo "  Samples kept as forward-only: $forward_kept"
            echo "=========================================="
            echo "✅ Dataset standardized to SINGLE-END format"
            echo "=========================================="
        } | tee -a "$report_file"
        
    elif [ "$paired_samples" -gt 0 ]; then
        echo "✅ Uniform PAIRED-END dataset. No standardization needed." | tee -a "$report_file"
    else
        echo "✅ Uniform SINGLE-END dataset. No standardization needed." | tee -a "$report_file"
    fi
    
    # ============================================================
    # Extract accession IDs using hyphen separator and verify against TSV
    # ============================================================
    echo "" | tee -a "$report_file"
    echo "========================================"
    echo "Extracting accession IDs from downloaded files..."
    echo "========================================" | tee -a "$report_file"
    
    local downloaded_file="${base_dir%/}/downloaded_files.txt"
    > "$downloaded_file"  # Clear/create file
    
    # Extract unique accession IDs from all FASTQ files
    # Uses the last hyphen (-) as separator to get the accession ID
    for file in "$fastq_path"/*.fastq; do
        [[ -f "$file" ]] || continue
        local basename=$(basename "$file")
        # Extract everything after the last hyphen, then remove suffixes
        local accession="${basename##*-}"   # Get part after last -
        accession="${accession%.fastq}"     # Remove .fastq extension
        accession="${accession%_1}"         # Remove _1 if present
        accession="${accession%_2}"         # Remove _2 if present
        echo "$accession"
    done | sort -u > "$downloaded_file"
    
    # Count downloaded and expected
    local downloaded_count=$(wc -l < "$downloaded_file" | tr -d ' ')
    local expected_sra_count=0
    while IFS=$'\t' read -r sra rename _; do
        [[ -n "$sra" && -n "$rename" ]] || continue
        ((expected_sra_count++))
    done < "${base_dir%/}/$acc"
    
    {
        echo "Expected accessions (from TSV): $expected_sra_count"
        echo "Downloaded accessions: $downloaded_count"
    } | tee -a "$report_file"
    
    # Check for mismatches and handle failed downloads
    if [ "$downloaded_count" -ne "$expected_sra_count" ]; then
        {
            echo "=========================================="
            echo "⚠️  DOWNLOAD COUNT MISMATCH DETECTED!"
            echo "=========================================="
            echo "Identifying failed downloads..."
        } | tee -a "$report_file"
        
        # Create temp file for failed accessions
        local temp_failed="${base_dir%/}/failed_accessions.tmp"
        > "$temp_failed"
        
        # Check each expected accession and identify failures
        while IFS=$'\t' read -r sra rename _; do
            [[ -n "$sra" ]] || continue
            if ! grep -q "^${sra}$" "$downloaded_file"; then
                echo "  ❌ Failed: $sra (prefix: $rename)" | tee -a "$report_file"
                echo "$sra" >> "$temp_failed"
            fi
        done < "${base_dir%/}/$acc"
        
        # Remove failed accessions from the TSV file
        if [ -s "$temp_failed" ]; then
            local failed_count=$(wc -l < "$temp_failed" | tr -d ' ')
            echo "" | tee -a "$report_file"
            echo "Removing $failed_count failed entries from $acc..." | tee -a "$report_file"
            
            local temp_tsv="${base_dir%/}/${acc}.tmp"
            > "$temp_tsv"
            
            # Rewrite TSV without failed entries
            while IFS=$'\t' read -r sra rename rest; do
                [[ -n "$sra" ]] || continue
                if ! grep -q "^${sra}$" "$temp_failed"; then
                    if [[ -n "$rest" ]]; then
                        echo -e "${sra}\t${rename}\t${rest}" >> "$temp_tsv"
                    else
                        echo -e "${sra}\t${rename}" >> "$temp_tsv"
                    fi
                fi
            done < "${base_dir%/}/$acc"
            
            # Replace original TSV with cleaned version
            mv "$temp_tsv" "${base_dir%/}/$acc"
            rm "$temp_failed"
            
            {
                echo "✅ Updated $acc - removed $failed_count failed entries"
                echo "=========================================="
            } | tee -a "$report_file"
        fi
    else
        echo "✅ All expected accessions downloaded successfully" | tee -a "$report_file"
    fi
    
    # ============================================================
    # Validate final FASTQ file count against expected samples
    # ============================================================
    echo "" | tee -a "$report_file"
    echo "========================================"
    echo "Validating download completeness..."
    echo "========================================"
    
    # Count expected samples from TSV (non-empty lines with valid SRA and rename prefix)
    declare -A expected_samples
    local expected_count=0
    while IFS=$'\t' read -r sra rename _; do
        [[ -n "$sra" && -n "$rename" ]] || continue
        expected_samples["$rename"]=1
        ((expected_count++))
    done < "${base_dir%/}/$acc"
    
    # Count actual final FASTQ files
    declare -A actual_samples
    local actual_count=0
    for file in "$fastq_path"/*.fastq; do
        [[ -f "$file" ]] || continue
        local basename=$(basename "$file")
        local prefix="${basename%.fastq}"
        # Remove _1 or _2 suffix if present (for paired-end files)
        prefix="${prefix%_1}"
        prefix="${prefix%_2}"
        actual_samples["$prefix"]=1
    done
    actual_count=${#actual_samples[@]}
    
    # Count final files (including _1, _2 suffixes)
    local final_file_count=$(find "$fastq_path" -type f -name "*.fastq" | wc -l)
    final_file_count=$((final_file_count))  # Remove leading spaces
    
    {
        echo "Expected samples (from TSV): $expected_count"
        echo "Actual unique samples: $actual_count"
        echo "Total FASTQ files: $final_file_count"
    } | tee -a "$report_file"
    
    # Determine if counts match expectations
    local validation_passed=0
    
    # After mixed dataset processing, all samples should be single-end (1 file per sample)
    # For uniform paired-end, expect 2 files per sample
    # For uniform single-end, expect 1 file per sample
    
    if [ "$single_samples" -gt 0 ] && [ "$paired_samples" -gt 0 ]; then
        # Mixed dataset - after standardization, should have 1 file per sample
        if [ "$actual_count" -eq "$expected_count" ] && [ "$final_file_count" -eq "$expected_count" ]; then
            validation_passed=1
        fi
    elif [ "$paired_samples" -gt 0 ]; then
        # Uniform paired-end - should have 2 files per sample (_1 and _2)
        if [ "$actual_count" -eq "$expected_count" ] && [ "$final_file_count" -eq $((expected_count * 2)) ]; then
            validation_passed=1
        fi
    else
        # Uniform single-end - should have 1 file per sample
        if [ "$actual_count" -eq "$expected_count" ] && [ "$final_file_count" -eq "$expected_count" ]; then
            validation_passed=1
        fi
    fi
    
    if [ "$validation_passed" -eq 1 ]; then
        {
            echo "=========================================="
            echo "✅ VALIDATION PASSED"
            echo "All expected samples have been successfully downloaded and processed."
            echo "=========================================="
        } | tee -a "$report_file"
    else
        {
            echo "=========================================="
            echo "❌ VALIDATION FAILED"
            echo "File count mismatch detected!"
            echo "=========================================="
        } | tee -a "$report_file"
        
        # Identify missing samples
        declare -a missing_samples=()
        for expected in "${!expected_samples[@]}"; do
            if [[ ! -v actual_samples["$expected"] ]]; then
                missing_samples+=("$expected")
            fi
        done
        
        if [ ${#missing_samples[@]} -gt 0 ]; then
            {
                echo ""
                echo "Missing samples (failed to download/process):"
                for missing in "${missing_samples[@]}"; do
                    # Find the original SRA accession from TSV
                    while IFS=$'\t' read -r sra rename _; do
                        if [[ "$rename" == "$missing" ]]; then
                            echo "  - Sample prefix: $missing (SRA: $sra)"
                            break
                        fi
                    done < "${base_dir%/}/$acc"
                done
                echo ""
                echo "Total missing samples: ${#missing_samples[@]}"
            } | tee -a "$report_file"
        fi
        
        # Identify unexpected samples (shouldn't happen, but check anyway)
        declare -a unexpected_samples=()
        for actual in "${!actual_samples[@]}"; do
            if [[ ! -v expected_samples["$actual"] ]]; then
                unexpected_samples+=("$actual")
            fi
        done
        
        if [ ${#unexpected_samples[@]} -gt 0 ]; then
            {
                echo ""
                echo "Unexpected samples (not in TSV):"
                for unexpected in "${unexpected_samples[@]}"; do
                    echo "  - $unexpected"
                done
                echo ""
                echo "Total unexpected samples: ${#unexpected_samples[@]}"
            } | tee -a "$report_file"
        fi
        
        {
            echo "=========================================="
            echo "Please check the log for details and retry failed downloads."
            echo "Log file: $report_file"
            echo "=========================================="
        } | tee -a "$report_file"
    fi
    
    echo "All done."
}